\chapter{Training}
a Reinforcement Learning Agent for Collaborative Transport of Cable Suspended Payloads with Multiple Multirotors
\section{Modular Reward Function Design}
\subsection{Stability Reward}
\subsection{Tracking Reward}
\subsection{Reward Function for Multi Quadrotor Control with Payload}

\section{Policy Training}
\subsection{Network Architecture}
\begin{itemize}
    \item MLP
    \item actor critic, privileged critic
    \item Recurrent?
    \item Taking the action mean for rollout
\end{itemize}
\subsection{Hyperparameters}
\begin{itemize}
    \item add list of relevant hyperparameters
    \item maybe list 2 configs -> one for fast prototyping and one for final robust training
    \item Explain the hyperparameters reasoning
\end{itemize}
\subsection{Comparing Centralized PPO, IPPO, and MAPPO}

\begin{itemize}
    \item 3 Plots with training (episode-length over steps) with 3 different seeds each
\end{itemize}




