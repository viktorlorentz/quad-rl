\chapter{Conclusion}

In this work, we have presented a unified framework for training \gls{rl} controllers capable of performing both single- and multi-quadrotor cable-suspended payload transport. By leveraging large-scale parallel simulation, carefully designed exponential-decay reward terms, and selective domain randomization of physical parameters, we obtained policies that recover gracefully from severe disturbances and generalize zero-shot from position holding to figure-eight trajectory tracking, performing better than the state of the art baseline methods.

Our experiments demonstrate that regularizing action outputs and including a short history of past commands yields smooth thrust profiles, eliminating bang-bang behavior and enabling preliminary sim-to-real transfer. Cooperative control scales to teams of up to four vehicles, with each additional agent contributing to improved payload stability, though performance degradation under extreme initial conditions highlighting inherent coordination challenges.

Through statistical analysis of 1,000 recovery rollouts per configuration and qualitative visualization of recovery and trajectory-tracking runs, we have shown that the learned policies maintain stable hover for extended periods and follow paths with high accuracy. Domain randomization of thrust coefficients, initial poses, and sensor noise proved sufficient to confer robustness to parameter variations and estimation errors, while holding payload mass and cable length fixed kept learning tractable.

Despite these achievements, several open questions remain. Extending the policies to handle obstacle avoidance, heterogeneous teams, and dynamic environments will require integration of higher-level planning and safety constraints. Moreover, closing the sim-to-real gap in outdoor settings with wind and noise calls for adaptive domain randomization curricula and online estimation of latent parameters such as cable tension. Exploring off-policy and meta-learning algorithms may further improve sample efficiency and rapid adaptation to new payloads.

By open sourcing our software framework \texttt{CrazyMarl}, which provides end to end high performance JAX training for Crazyflie swarms, along with our methodology, evaluation scripts and trained models, we aim to accelerate progress toward robust fully autonomous aerial transport with a team of quadrotors. The demonstrated ability of \gls{rl} to produce agile coordinated flight behaviors lays the groundwork for practical applications such as autonomous delivery, infrastructure inspection and collaborative assembly tasks.